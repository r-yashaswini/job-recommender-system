{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7217a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FreshersRecruitment scraper... (Last 30 days)\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/1/\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/2/\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/3/\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/4/\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/5/\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/6/\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/7/\n",
      "Fetching: https://freshersrecruitment.co.in/category/jobs/page/8/\n",
      "Reached cutoff date: 2025-12-28\n",
      "Found 76 job listings. Enriching details...\n",
      "Processing job 1/76: Wipro Off Campus Jobs 2026 | Hiring for Freshers |...\n",
      "Processing job 2/76: GE Aerospace Internship 2026 | Hiring for Freshers...\n",
      "Processing job 3/76: ServiceNow Recruitment 2026 | Hiring for Freshers ...\n",
      "Processing job 4/76: Synopsys Recruitment 2026 | DevOps Engineer Opport...\n",
      "Processing job 5/76: Cognizant Walk-in Interview 2026 | Technical Suppo...\n",
      "Processing job 6/76: Sutherland Walk-in Drive 2026 | Hiring for Fresher...\n",
      "Processing job 7/76: Tech Mahindra Walk-in Interview 2026 | Hiring for ...\n",
      "Processing job 8/76: Wipro Off Campus Hiring 2026 | Recruitment for Fre...\n",
      "Processing job 9/76: American Express Off Campus Drive 2026 | Mass Hiri...\n",
      "Processing job 10/76: L&T Off Campus Drive 2026 | Hiring M.Tech Freshers...\n",
      "Processing job 11/76: GE Healthcare Off Campus Drive 2026 | Hiring for F...\n",
      "Processing job 12/76: Capgemini Hiring 2026 | Mass Recruitment for Fresh...\n",
      "Processing job 13/76: Oracle Recruitment 2026 | Associate Consultant Opp...\n",
      "Processing job 14/76: Qualcomm Recruitment 2026 | Hiring Freshers Role O...\n",
      "Processing job 15/76: Siemens Off Campus Drive 2026 | A Great Opportunit...\n",
      "Processing job 16/76: Micron Technology Recruitment 2026 | Hiring for Fr...\n",
      "Processing job 17/76: Infosys Recruitment for 2026 Batch | Hiring for Fr...\n",
      "Processing job 18/76: Deloitte Off Campus Jobs 2026 | Hiring Analyst (PL...\n",
      "Processing job 19/76: Tata Motors Off Campus Drive 2026 | Senior Manager...\n",
      "Processing job 20/76: Microsoft Off Campus Drive 2026 | Software Enginee...\n",
      "Processing job 21/76: IDFC FIRST Bank Recruitment 2026 | Hiring Freshers...\n",
      "Processing job 22/76: Hitachi Recruitment 2026 | Executive Diploma Train...\n",
      "Processing job 23/76: Caterpillar Off Campus Drive 2026 | Mass Hiring Fr...\n",
      "Processing job 24/76: NTT DATA Recruitment 2026 | Hiring for Freshers | ...\n",
      "Processing job 25/76: GE Healthcare Recruitment 2026 | Freshers Jobs | G...\n",
      "Processing job 26/76: Citigroup Off Campus Drive 2026 | Hiring for Fresh...\n",
      "Processing job 27/76: Barclays Off Campus Jobs 2026 | Hiring Freshers | ...\n",
      "Processing job 28/76: Maruti Suzuki Recruitment 2026 | Mass Hiing for Fr...\n",
      "Processing job 29/76: Deloitte Hiring for 2026 Batch | Recruitment for F...\n",
      "Processing job 30/76: Amazon Off Campus Drive 2026 | Mass Hiring for Fre...\n",
      "Processing job 31/76: Capgemini Recruitment 2026 | Hiring for Freshers |...\n",
      "Processing job 32/76: Apple Recruitment 2026 | Mass Hiring Role of Junio...\n",
      "Processing job 33/76: Infosys Internship 2026 | A Great Opportunity to K...\n",
      "Processing job 34/76: Virtusa Off Campus Drive 2026 | Recruitment for Fr...\n",
      "Processing job 35/76: Synopsys Off Campus Drive 2026 | Hiring for Freshe...\n",
      "Processing job 36/76: Cognizant GenC Recruitment 2026 | Mass Hiring for ...\n",
      "Processing job 37/76: GlobalLogic Off Campus Drive 2026 | Hiring Fresher...\n",
      "Processing job 38/76: TCS MBA Hiring for 2026 Batch | Recruitment for Fr...\n",
      "Processing job 39/76: ZOHO Corp Recruitment for 2026 Batch | Mass Hiring...\n",
      "Processing job 40/76: Accenture Careers Jobs 2026 | Hiring Freshers Role...\n",
      "Processing job 41/76: IBM Recruitment for 2026 Batch | Hiring Associate ...\n",
      "Processing job 42/76: Infosys EdgeVerve Systems Recruitment 2026 | Hirin...\n",
      "Processing job 43/76: Cisco Recruitment 2026 | Hiring Freshers for 2025 ...\n",
      "Processing job 44/76: Maruti Suzuki Off Campus Drive 2026 | Hiring for F...\n",
      "Processing job 45/76: Deloitte Recruitment for 2026 Batch | National Lev...\n",
      "Processing job 46/76: Hexaware Walk-in Drive 2026 | Mass Hiring for Fres...\n",
      "Processing job 47/76: Wipro Work Integrated Learning Program 2026 | Hiri...\n",
      "Processing job 48/76: Genpact Walk-in Drive 2026 | Hiring for Freshers |...\n",
      "Processing job 49/76: S&P Global Software Engineer 2026 | Hiring for Fre...\n",
      "Processing job 50/76: Capgemini Exceller Hiring 2026 | 2025 & 2026 Batch...\n",
      "Processing job 51/76: Cognizant Walk-in Drive 2026 | Analyst Trainee Opp...\n",
      "Processing job 52/76: TCS NQT (National Qualifier Test) 2026 | Hiring Fr...\n",
      "Processing job 53/76: Dell Technologies Recruitment 2026 | Hiring for Fr...\n",
      "Processing job 54/76: Qualcomm Off Campus Drive 2026 | Hiring Freshers o...\n",
      "Processing job 55/76: JPMorgan Chase Recruitment 2026 : Mass Hiring for ...\n",
      "Processing job 56/76: Adobe Off Campus Drive 2026 | Hiring for Freshers ...\n",
      "Processing job 57/76: HPE Recruitment 2026 | Mass Hiring for Freshers | ...\n",
      "Processing job 58/76: Salesforce Off Campus Drive 2026 | Hiring for Fres...\n",
      "Processing job 59/76: Yash Technologies Recruitment 2026 | Mass Hiring f...\n",
      "Processing job 60/76: IBM Off Campus Drive 2026 | Hiring Freshers for As...\n",
      "Processing job 61/76: Deloitte Recruitment 2026 | Hiring Freshers Role o...\n",
      "Processing job 62/76: Tech Mahindra Off Campus Drive 2026 | Apply for SQ...\n",
      "Processing job 63/76: IDFC FIRST Bank Recruitment 2026 | SDET Opportunit...\n",
      "Processing job 64/76: ZOHO Corp Off Campus Drive 2026 | A Great Opportun...\n",
      "Processing job 65/76: Accenture Hiring 2026 | Mass Recruitment Freshers ...\n",
      "Processing job 66/76: Honeywell Recruitment 2026 | Hiring for Freshers |...\n",
      "Processing job 67/76: Ericsson Off Campus Drive 2026 | Network Engineer ...\n",
      "Processing job 68/76: Amazon Recruitment 2026 | Hiring Freshers as Devic...\n",
      "Processing job 69/76: Cognizant GenC Off Campus Drive 2026 | Mass Hiring...\n",
      "Processing job 70/76: Google Recruitment 2026 | Hiring Freshers for 2025...\n",
      "Processing job 71/76: Mphasis Off Campus Drive 2026 | Hiring for Fresher...\n",
      "Processing job 72/76: Amazon Work From Home Jobs 2026 | A Great Opportun...\n",
      "Processing job 73/76: Wipro Off Campus Drive 2026 | Hiring Role for Appl...\n",
      "Processing job 74/76: NTT DATA Recruitment 2026 | Hiring for Freshers | ...\n",
      "Processing job 75/76: TCS Atlas Hiring 2026 | A Great Opportunity for Fr...\n",
      "Processing job 76/76: Accenture Recruitment 2026 | Hiring for Freshers |...\n",
      "Scraping completed. Total jobs: 78\n",
      "\n",
      "First 5 jobs:\n",
      "                                               title posted_date   location  \\\n",
      "0  Wipro Off Campus Jobs 2026 | Hiring for Freshe...  2026-01-27     Mumbai   \n",
      "1  GE Aerospace Internship 2026 | Hiring for Fres...  2026-01-27  Bangalore   \n",
      "2  ServiceNow Recruitment 2026 | Hiring for Fresh...  2026-01-27  Hyderabad   \n",
      "3  Synopsys Recruitment 2026 | DevOps Engineer Op...  2026-01-27       Pune   \n",
      "4  Cognizant Walk-in Interview 2026 | Technical S...  2026-01-27    Gurgaon   \n",
      "\n",
      "     experience  \n",
      "0      Freshers  \n",
      "1      Freshers  \n",
      "2  0 – 2+ Years  \n",
      "3     1–2 Years  \n",
      "4   0 – 2 Years  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/87.0.4280.141 Safari/537.36 '\n",
    "                  'Edg/87.0.664.75'\n",
    "}\n",
    "\n",
    "BLOCKED_KEYWORDS = {'telegram', 'freshersrecruitment', 'whatsapp'}\n",
    "DAYS_BACK = 30\n",
    "\n",
    "print(f\"Starting FreshersRecruitment scraper... (Last {DAYS_BACK} days)\")\n",
    "\n",
    "today = datetime.today().date()\n",
    "cutoff_date = today - timedelta(days=DAYS_BACK)\n",
    "\n",
    "page_num = 1\n",
    "stop_pagination = False\n",
    "job_details = []\n",
    "while not stop_pagination:\n",
    "    page_url = f\"https://freshersrecruitment.co.in/category/jobs/page/{page_num}/\"\n",
    "    print(f\"Fetching: {page_url}\")\n",
    "\n",
    "    soup = None\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response = requests.get(page_url, headers=HEADERS, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if attempt == 2:\n",
    "                print(f\"Failed to fetch page {page_num}: {e}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "\n",
    "    if not soup:\n",
    "        break\n",
    "\n",
    "    articles = soup.find_all(\"article\")\n",
    "    if not articles:\n",
    "        break\n",
    "\n",
    "    for article in articles:\n",
    "        job = {}\n",
    "\n",
    "        title_tag = article.find(\"h2\", class_=\"entry-title\")\n",
    "        if title_tag:\n",
    "            a_tag = title_tag.find(\"a\", href=True)\n",
    "            if a_tag:\n",
    "                job[\"title\"] = a_tag.get_text(strip=True)\n",
    "                job[\"listing_url\"] = a_tag[\"href\"]\n",
    "\n",
    "        time_tag = article.find(\"time\")\n",
    "        if time_tag:\n",
    "            try:\n",
    "                posted_date = datetime.strptime(\n",
    "                    time_tag.get_text(strip=True), \"%B %d, %Y\"\n",
    "                ).date()\n",
    "                job[\"posted_date\"] = posted_date\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        if job.get(\"posted_date\") and job[\"posted_date\"] < cutoff_date:\n",
    "            print(f\"Reached cutoff date: {job['posted_date']}\")\n",
    "            stop_pagination = True\n",
    "            break\n",
    "\n",
    "        if job.get(\"listing_url\"):\n",
    "            job_details.append(job)\n",
    "\n",
    "    page_num += 1\n",
    "\n",
    "print(f\"Found {len(job_details)} job listings. Enriching details...\")\n",
    "\n",
    "enriched_jobs = []\n",
    "\n",
    "for i, job in enumerate(job_details, 1):\n",
    "    print(f\"Processing job {i}/{len(job_details)}: {job['title'][:50]}...\")\n",
    "\n",
    "    job_soup = None\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response = requests.get(job[\"listing_url\"], headers=HEADERS, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            job_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            break\n",
    "        except Exception:\n",
    "            time.sleep(2 ** attempt)\n",
    "\n",
    "    if not job_soup:\n",
    "        continue\n",
    "\n",
    "    job_info = job.copy()\n",
    "\n",
    "    apply_urls = set()\n",
    "    for a in job_soup.find_all(\"a\", href=True):\n",
    "        anchor_text = a.get_text(strip=True).lower()\n",
    "        if any(x in anchor_text for x in (\"apply here\", \"click here\", \"apply now\")):\n",
    "            apply_url = a[\"href\"]\n",
    "            if not any(b in apply_url.lower() for b in BLOCKED_KEYWORDS):\n",
    "                apply_urls.add(apply_url)\n",
    "\n",
    "    if apply_urls:\n",
    "        job_info[\"apply_urls\"] = list(apply_urls)\n",
    "\n",
    "    for ul in job_soup.find_all(\"ul\", class_=\"wp-block-list\"):\n",
    "        for li in ul.find_all(\"li\"):\n",
    "            strong = li.find(\"strong\")\n",
    "            if strong:\n",
    "                label = strong.get_text(strip=True).lower()\n",
    "                value = li.get_text(strip=True).replace(\n",
    "                    strong.get_text(strip=True), \"\"\n",
    "                ).lstrip(\": \").strip()\n",
    "\n",
    "                if \"location\" in label:\n",
    "                    job_info[\"location\"] = value\n",
    "                elif \"experience\" in label:\n",
    "                    job_info[\"experience\"] = value\n",
    "\n",
    "    descriptions = []\n",
    "\n",
    "    for ul in job_soup.find_all(\"ul\", class_=\"wp-block-list\"):\n",
    "        for li in ul.find_all(\"li\"):\n",
    "            txt = li.get_text(strip=True)\n",
    "            if txt:\n",
    "                descriptions.append(txt)\n",
    "\n",
    "    for p in job_soup.find_all(\"p\"):\n",
    "        txt = p.get_text(strip=True)\n",
    "        if txt.startswith((\"•\", \"-\", \"–\", \"*\")):\n",
    "            descriptions.append(txt.lstrip(\"•-–* \").strip())\n",
    "\n",
    "    if descriptions:\n",
    "        job_info[\"description\"] = \" \".join(dict.fromkeys(descriptions))\n",
    "    else:\n",
    "        job_info[\"description\"] = (\n",
    "            \"No detailed description available. Please visit the apply link for more information.\"\n",
    "        )\n",
    "\n",
    "    enriched_jobs.append(job_info)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for job in enriched_jobs:\n",
    "    urls = job.get(\"apply_urls\", [])\n",
    "    if isinstance(urls, list) and urls:\n",
    "        for apply_url in urls:\n",
    "            if isinstance(apply_url, str) and not any(\n",
    "                b in apply_url.lower() for b in BLOCKED_KEYWORDS\n",
    "            ):\n",
    "                new_job = job.copy()\n",
    "                new_job[\"apply_url\"] = apply_url\n",
    "                new_job.pop(\"apply_urls\", None)\n",
    "                rows.append(new_job)\n",
    "    else:\n",
    "        new_job = job.copy()\n",
    "        new_job[\"apply_url\"] = job.get(\"listing_url\")\n",
    "        new_job.pop(\"apply_urls\", None)\n",
    "        rows.append(new_job)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df[\"location\"] = df[\"location\"].fillna(\"Across India\")\n",
    "df[\"experience\"] = df[\"experience\"].fillna(\"Freshers\")\n",
    "df[\"description\"] = df[\"description\"].fillna(\n",
    "    \"No detailed description available. Please visit the apply link for more information.\"\n",
    ")\n",
    "df[\"apply_url\"] = df[\"apply_url\"].fillna(df[\"listing_url\"])\n",
    "df[\"source\"] = \"freshersrecruitment\"\n",
    "\n",
    "print(f\"Scraping completed. Total jobs: {len(df)}\")\n",
    "\n",
    "print(\"\\nFirst 5 jobs:\")\n",
    "if \"posted_date\" in df.columns:\n",
    "    print(df[[\"title\", \"posted_date\", \"location\", \"experience\"]].head())\n",
    "else:\n",
    "    print(df[[\"title\", \"location\", \"experience\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c42cd57-93b5-4459-b7e1-56320a1f54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "DB_URL = \"postgresql+psycopg2://postgres:Sunny$123@localhost:35432/pgvector\"\n",
    "engine = create_engine(DB_URL)\n",
    "df.to_sql(\n",
    "    name=\"jobs\",\n",
    "    con=engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    "    chunksize=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
